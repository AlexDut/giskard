# üß™ Test your ML model

Because ML models depend on data, testing scenarios depend on the domain specificities and are often infinite. Giskard provides all the necessary tools that enable you to:
* Start wrtiting tests by detecting the vulnerabilities of your model (see the [Scan](../scan/index.rst) feature)
* Create reproducible test suites with fixtures that integrate the domain knowledge of your model
* Load the best tests from the Giskard open-source catalog

## 1. Execute a Giskard test

To create and execute a Giskard test, you have 2 possibilities. You can either load a test from the Giskard [catalog](../../catalogs/test-catalog/index.rst) or create your own test by decorating a Python function.

:::{hint}
In order to execute the test provided by Giskard. You first need to wrap your dataset and model to make them compatible with Giskard. See the [wrap your model](../wrap_model/index.md) and [wrap your dataset](../wrap_dataset/index.md) sections.
:::

### Load and execute a test from the Giskard Catalog

:::{hint}
You can see all our tests in the [üìñ Test Catalog](../../catalogs/test-catalog/index.rst)
:::


::::{tab-set}
:::{tab-item} Drift tests

Testing drifts enables you to make sure your model is still valid by checking if prediction and features in inference time is close to the ones used for training the model. Drift measures the difference in statistical distribution between a reference data, often the training set, and a ‚Äúcurrent‚Äù dataset, such as the test set or a batch of examples in inference time. To pick the right drift tests, have a look on our ressource ([numerical data drift](https://www.giskard.ai/knowledge/how-to-test-ml-models-3-n-numerical-data-drift) or [categorical data drift](https://www.giskard.ai/knowledge/how-to-test-ml-models-2-n-categorical-data-drift)) and [drift catalog](../../reference/tests/drift.rst) pages.

Thanks to Giskard, your drift tests can **focus on specific data slices** by passing a [slicing function](../slice/index.md) (generated by the scan for example) as parameter of your test.

```python
from giskard import demo, Model, Dataset, testing, slicing_function
import pandas as pd
model, df = demo.titanic()

wrapped_model = Model(model=model, model_type="classification")
train_df = Dataset(df=df.head(400), target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])
test_df = Dataset(df=df.tail(400), target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

# Create a slicing function on females to create more domain specific tests
@slicing_function(name="females")
def my_func2(row: pd.Series, threshold: int):
    return row['Sex'] == "female"

result = testing.test_drift_prediction_ks(model=wrapped_model, 
                                          actual_dataset=test_df, 
                                          reference_dataset=train_df,
                                          classification_label='yes',
                                          slicing_function=female_slice,
                                          threshold=0.5).execute()

print("Result for 'Classification Probability drift (Kolmogorov-Smirnov):")
print(f"Passed: {result.passed}")
print(f"Metric: {result.metric}")
```

:::

:::{tab-item} Performance tests

Performance tests

```python
from giskard import demo, Model, Dataset, testing

model, df = demo.titanic()

wrapped_model = Model(model=model, model_type="classification")
wrapped_dataset = Dataset(df=df, target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

result = testing.test_f1(dataset=wrapped_dataset, model=wrapped_model).execute()


print(f"result: {result.passed} with metric {result.metric}")
```

:::

:::{tab-item} Metamorphic tests

```python
from giskard import demo, Model, Dataset, testing, transformation_function

model, df = demo.titanic()

wrapped_model = Model(model=model, model_type="classification")
wrapped_dataset = Dataset(df=df, target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

@transformation_function
def add_three_years(row):
    row['Age'] = row['Age'] + 3
    return row

result = testing.test_metamorphic_invariance(model=wrapped_model,
                                             dataset=wrapped_dataset,
                                             transformation_function=add_three_years
                                             ).execute()

print(f"result: {result.passed} with metric {result.metric}")
```

See [üî™ Create slices and transformations function / Transformation](../../guides/slice/index.md)
to see how to create custom transformations

:::

:::{tab-item} Statistic tests

```python
from giskard import demo, Model, Dataset, testing

model, df = demo.titanic()

wrapped_model = Model(model=model, model_type="classification")
wrapped_dataset = Dataset(df=df, target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

result = testing.test_right_label(wrapped_model, wrapped_dataset, 'yes').execute()
print(f"result: {result.passed} with metric {result.metric}")
```

:::
::::

### Create and execute your own test

::::{tab-set}
:::{tab-item} Using function

```python
from giskard import test, Dataset, TestResult

@test(name="My Example", tags=["quality", "custom"])
def uniqueness_test_function(dataset: Dataset,
                             column_name: str = None,
                             category: str = None,
                             threshold: float = 0.5):
    freq_of_cat = dataset.df[column_name].value_counts()[category] / (len(dataset.df))
    passed = freq_of_cat < threshold

    return TestResult(passed=passed, metric=freq_of_cat)
```

#### Description

In order to define your own test function, you just need to declare a method with its parameters and return a result.
It's pretty simple, however, it does not allow autocompletion during the test suite creation, contrary to the
class-based method.

#### Usage \[Reference]

* <mark style="color:red;">**`parameters`**</mark> : **Your parameters need to have a type defined.** Here is the type
  allowed as your test parameters:
    * `Dataset` A giskard dataset, [wrap your dataset](../wrap_dataset/index.md)
    * `BaseModel` A giskard model, [wrap your model](../wrap_model/index.md)
    * `int/float/bool/str`  Any primitive type can be used
* <mark style="color:red;">**`return`**</mark> The result of your test must be either a bool or a TestResult:
    * `bool` Either `True` if the test passed or `False` if it failed
    * `TestResult` An object containing more details:

        * `passed` A required bool to know if the test passed
        * `metric` A float value with the score of the test

#### Set metadata to your test

In order to **set metadata** to your test, you need to use the `@test` decorator before your method or your class

* <mark style="color:red;">**`name`**</mark> : A custom name that will be visible in the application
* <mark style="color:red;">**`tags`**</mark> : A list of tags that allow you to quickly identify your tests
  :::

:::{tab-item} Using test class

```python
from giskard import GiskardTest, Dataset, TestResult


class DataQuality(GiskardTest):

    def __init__(self,
                 dataset: Dataset = None,
                 threshold: float = 0.5,
                 column_name: str = None,
                 category: str = None):
        self.dataset = dataset
        self.threshold = threshold
        self.column_name = column_name
        self.category = category
        super().__init__()

    def execute(self) -> TestResult:
        freq_of_cat = self.dataset.df[self.column_name].value_counts()[self.category] / (len(self.dataset.df))
        passed = freq_of_cat < self.threshold

        return TestResult(passed=passed, metric=freq_of_cat)
```

#### Description

In order to define your own test class, you need to extends `GiskardTest` and implement the `execute` method

#### Main methods \[Reference]

* <mark style="color:red;">**`__init__`**</mark> : The initialisation method must be implemented in order to specify the
  required parameters of your test. **It is also required to call the parent initialization method**
  calling `super().__init__()`. **Your parameters need to have a type and default value specified.** You can should use
  **None** as a default value if you require a parameter to be specified. Here is the type allowed in the init method:
    * `Dataset` A giskard dataset, [wrap your dataset](../wrap_dataset/index.md)
    * `BaseModel` A giskard model, [wrap your model](../wrap_model/index.md)
    * `int/float/bool/str`  Any primitive type can be used
* <mark style="color:red;">**`execute`**</mark> The execute method will be called to perform the test, you will be able
  to access all the parameters set by the initialization method. Your method can return two type of results:
    * `bool` Either `True` if the test passed or `False` if it failed
    * `TestResult` An object containing more details:
        * `passed` A required bool to know if the test passed
        * `metric` A float value with the score of the test

:::
::::

## 3. Create & Execute a test suite

:::{hint}
You can see all our tests in the [üìñ Test Catalog](../../guides/test-catalog/index.rst)
:::

A test suite is a collection of tests that can be parameterized to accommodate various scenarios. Each test within the
suite may have some parameters left unspecified. When executing the test suite, you can provide the missing parameters
through the run method. This allows for flexible and customizable test execution based on your specific needs.
::::{tab-set}

:::{tab-item} Model as input
Example using a two performance tests

```python
from giskard import demo, Model, Dataset, testing, Suite

model, df = demo.titanic()

wrapped_dataset = Dataset(df=df, target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

# Create a suite and add a F1 test and an accuracy test
# Note that all the parameters are specified except model
# Which means that we will need to specify model everytime we run the suite
suite = Suite() \
    .add_test(testing.test_f1(dataset=wrapped_dataset)) \
    .add_test(testing.test_accuracy(dataset=wrapped_dataset))

# Create our first model
my_first_model = Model(model=model, model_type="classification")

# Run the suite by specifying our model and display the results
passed, results = suite.run(model=my_first_model)

# Create an improved version of our model
my_improved_model = Model(model=model, model_type="classification")

# Run the suite with our new version and check if the results improved
suite.run(model=my_improved_model)
```

#### Description

In this example we create a Suite with two tests, `test_f1` and `test_accuracy`. We specified all the parameters expect
the dataset to "expose" it as a run input. We can see that the way to set parameters differ whenever we are dealing with
a test class or a test function.

:::

:::{tab-item} Dataset as input
```python
import pandas as pd
from giskard import demo, Model, Dataset, testing, Suite, transformation_function, slicing_function

model, df = demo.titanic()

wrapped_model = Model(model=model, model_type="classification")

@transformation_function
def transform(df: pd.Series) -> pd.Series:
    df['Age'] = df['Age'] + 10
    return df

@slicing_function(row_level=False, name='female')
def slice_female(df: pd.DataFrame) -> pd.DataFrame:
    return df[df.Sex == 'female']

@slicing_function(row_level=False, name='male')
def slice_male(df: pd.DataFrame) -> pd.DataFrame:
    return df[df.Sex == 'male']

# Create a suite and add a disparate impact test and a metamorphic test
# Note that all the parameters are specified except dataset
# Which means that we will need to specify dataset everytime we run the suite
suite = Suite() \
    .add_test(testing.test_disparate_impact(model=wrapped_model, protected_slicing_function=slice_female,
                                                       unprotected_slicing_function=slice_male, positive_outcome="yes")) \
    .add_test(testing.test_metamorphic_invariance(model=wrapped_model, transformation_function=transform))

# Create our first dataset
my_first_dataset = Dataset(df=df, target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

# Run the suite by specifying our model and display the results
passed, results = suite.run(dataset=my_first_dataset)

# Create an updated version of the dataset
my_updated_dataset =  Dataset(df=df, target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

# Run the suite with our new version and check if the results improved
suite.run(dataset=my_updated_dataset)
```
:::

:::{tab-item} Shared test input
```python
from giskard import demo, Model, Dataset, testing, Suite, SuiteInput, slicing_function
import pandas as pd

model, df = demo.titanic()

wrapped_model = Model(model=model, model_type="classification")
wrapped_dataset = Dataset(df=df, target="Survived", cat_columns=['Pclass', 'Sex', "SibSp", "Parch", "Embarked"])

@slicing_function(row_level=False, name='female')
def slice_female(df: pd.DataFrame) -> pd.DataFrame:
    return df[df.Sex == 'female']

sliced_dataset = wrapped_dataset.slice(slice_female)

shared_input = SuiteInput("dataset", Dataset)

suite = Suite() \
    .add_test(testing.test_auc(dataset=shared_input, threshold=0.2)) \
    .add_test(testing.test_f1(dataset=shared_input, threshold=0.2)) \
    .add_test(testing.test_diff_f1(threshold=0.2, actual_dataset=shared_input))

suite.run(model=wrapped_model, dataset=wrapped_dataset, reference_dataset=sliced_dataset)
```
:::
::::



:::{hint}
To upload your test suite to the Giskard server, go to [Upload objects](../../guides/upload/index.md) to the Giskard server.
:::
