title: Performance
id: performance
order: 3
items:
  - id: auc
    title: AUC
    hint: Test if the AUC is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      """
      Detailed description : Test if the model AUC performance is higher than a threshold
      for a given sub-population.

      Examples : The test is passed when the AUC for women is higher than 0.7

      Inputs :
              - df_slice(pandas.Dataframe): sub-population of the test dataset selected
                during Test Suite Creation
              - model : model selected during Test Suite Creation
              - threshold : threshold value of AUC metrics
              - target : target column name

      Outputs :
              - total rows tested  : length of df_slice tested
              - metric :  the AUC performance metric
              - passed : TRUE if AUC metrics > threshold
      """
      tests.performance.test_auc(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )

  - id: f1
    title: F1
    hint: Test if the F1 score is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_f1(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_f1
    title: F1 difference
    hint: Test if the F1 score is equal between two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_diff_f1(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: accuracy
    title: Accuracy
    hint: Test if the Accuracy is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_accuracy(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_accuracy
    title: Accuracy difference
    hint: Test if the Accuracy is equal between the two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_diff_accuracy(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: precision
    title: Precision
    hint: Test if the Precision is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_precision(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_precision
    title: Precision difference
    hint: Test if the Precision is equal between the two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_diff_precision(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: recall
    title: Recall
    hint: Test if the Recall is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_recall(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_recall
    title: Recall difference
    hint: Test if the Recall is equal between the two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_diff_recall(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: neg_rmse
    title: Negative RMSE
    hint: Test if  the negative Root Mean Square Error value is low enough for the dataset
    modelTypes: REGRESSION
    # language=Python
    code: |-
      tests.performance.test_neg_rmse(
          df=test_df,
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: neg_mae
    title: Negative MAE
    hint: Test if  the negative Mean Absolute Error value is low enough for the dataset
    modelTypes: REGRESSION
    # language=Python
    code: |-
      tests.performance.test_neg_mae(
          df=test_df,
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: r2
    title: R2
    hint: Test if  the R-Squared value is high enough for the dataset
    modelTypes: REGRESSION
    # language=Python
    code: |-
      tests.performance.test_r2(
          df=test_df,
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
