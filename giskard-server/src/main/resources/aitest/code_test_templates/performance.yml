title: Performance
id: performance
order: 3
items:
  - id: auc
    title: AUC
    hint: Test if the AUC is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      """
        Test if the model AUC performance is higher than a threshold

        Args:
            df_slice(pandas.core.frame.DataFrame):
                sub-population of the test dataset selected during Test Suite Creation
            model(class ModelInspector):
                model selected during Test Suite Creation
            target(str):
                target column name
            threshold(int):
                threshold value of AUC metrics

        Returns:
            total rows tested:
                length of df_slice tested
            metric:
                the AUC performance metric
            passed:
                TRUE if AUC metrics > threshold

        """
      tests.performance.test_auc(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )

  - id: f1
    title: F1
    hint: Test if the F1 score is high enough for a sub-population
    # language=Python
    code: |-
      """
        Test if the model F1 score is higher than a defined threshold for a given sub-population

        Args:
            df_slice(pandas.core.frame.DataFrame):
                sub-population of the test dataset selected during Test Suite Creation
            model(class ModelInspector):
                model selected during Test Suite Creation
            target(str):
                target column name
            threshold(int):
                threshold value for F1 Score

        Returns:
            total rows tested:
                length of df_slice tested
            metric:
                the F1 score metric
            passed:
                TRUE if F1 Score metrics > threshold
      """
      tests.performance.test_f1(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_f1
    title: F1 difference
    hint: Test if the F1 score is equal between two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_diff_f1(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: accuracy
    title: Accuracy
    hint: Test if the Accuracy is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_accuracy(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_accuracy
    title: Accuracy difference
    hint: Test if the Accuracy is equal between the two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      """
        Test if the model Accuracy is higher than a threshold for a given sub-population

        Args:
            df_slice(pandas.core.frame.DataFrame):
                sub-population of the test dataset selected during Test Suite Creation
            model(ModelInspector):
                model selected during Test Suite Creation
            target(str):
                target column name
            threshold(int):
                threshold value for Accuracy

        Returns:
            total rows tested:
                length of df_slice tested
            metric:
                the Accuracy metric
            passed:
                TRUE if Accuracy metrics > threshold

        """
      tests.performance.test_diff_accuracy(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: precision
    title: Precision
    hint: Test if the Precision is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_precision(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_precision
    title: Precision difference
    hint: Test if the Precision is equal between the two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_diff_precision(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: recall
    title: Recall
    hint: Test if the Recall is high enough for a sub-population
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_recall(
          df_slice=test_df[:len(test_df) // 2],
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: diff_recall
    title: Recall difference
    hint: Test if the Recall is equal between the two samples
    modelTypes:
      - MULTICLASS_CLASSIFICATION
      - BINARY_CLASSIFICATION
    # language=Python
    code: |-
      tests.performance.test_diff_recall(
          df=test_df,
          model=model,
          filter_1=test_df[:len(test_df)//2].index,
          filter_2=test_df[len(test_df)//2:].index,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: neg_rmse
    title: Negative RMSE
    hint: Test if  the negative Root Mean Square Error value is low enough for the dataset
    modelTypes:
      - REGRESSION
    # language=Python
    code: |-
      tests.performance.test_neg_rmse(
          df=test_df,
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: neg_mae
    title: Negative MAE
    hint: Test if  the negative Mean Absolute Error value is low enough for the dataset
    modelTypes:
      - REGRESSION
    # language=Python
    code: |-
      tests.performance.test_neg_mae(
          df=test_df,
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
  - id: r2
    title: R2
    hint: Test if  the R-Squared value is high enough for the dataset
    modelTypes:
     - REGRESSION
    # language=Python
    code: |-
      tests.performance.test_r2(
          df=test_df,
          model=model,
          threshold=0.1,
          target='<TARGET COLUMN>'
      )
